Title: Models - OpenAI API

URL Source: https://platform.openai.com/docs/models

Markdown Content:
Explore all available models and compare their capabilities.

Featured models

Frontier models

OpenAI's most advanced models, recommended for most tasks.

Open-weight models

Open-weight models under a permissive Apache 2.0 license.

Specialized models

Purpose-built for specific tasks.

Realtime and audio models

Models for audio use cases and realtime inputs and outputs.

ChatGPT models

Models used in ChatGPT, not recommended for API use.

All models

Diverse models for a variety of tasks.

[![Image 1: gpt-5](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-5.png) GPT-5 The best model for coding and agentic tasks across domains](https://platform.openai.com/docs/models/gpt-5)[![Image 2: gpt-5-mini](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-5-mini.png) GPT-5 mini A faster, cost-efficient version of GPT-5 for well-defined tasks](https://platform.openai.com/docs/models/gpt-5-mini)[![Image 3: gpt-5-nano](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-5-nano.png) GPT-5 nano Fastest, most cost-efficient version of GPT-5](https://platform.openai.com/docs/models/gpt-5-nano)[![Image 4: gpt-5-codex](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-5-codex.png) GPT-5-Codex A version of GPT-5 optimized for agentic coding in Codex](https://platform.openai.com/docs/models/gpt-5-codex)[![Image 5: o3-deep-research](https://cdn.openai.com/API/docs/images/model-page/model-icons/o3-deep-research.png) o3-deep-research Our most powerful deep research model](https://platform.openai.com/docs/models/o3-deep-research)[![Image 6: o4-mini-deep-research](https://cdn.openai.com/API/docs/images/model-page/model-icons/o4-mini-deep-research.png) o4-mini-deep-research Faster, more affordable deep research model](https://platform.openai.com/docs/models/o4-mini-deep-research)[![Image 7: o3-pro](https://cdn.openai.com/API/docs/images/model-page/model-icons/o3-pro.png) o3-pro Version of o3 with more compute for better responses](https://platform.openai.com/docs/models/o3-pro)[![Image 8: gpt-audio](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-audio.png) gpt-audio For audio inputs and outputs with Chat Completions API](https://platform.openai.com/docs/models/gpt-audio)[![Image 9: gpt-realtime](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-realtime.png) gpt-realtime Model capable of realtime text and audio inputs and outputs](https://platform.openai.com/docs/models/gpt-realtime)[![Image 10: o3](https://cdn.openai.com/API/docs/images/model-page/model-icons/o3.png) o3 Reasoning model for complex tasks, succeeded by GPT-5](https://platform.openai.com/docs/models/o3)[![Image 11: o4-mini](https://cdn.openai.com/API/docs/images/model-page/model-icons/o4-mini.png) o4-mini Fast, cost-efficient reasoning model, succeeded by GPT-5 mini](https://platform.openai.com/docs/models/o4-mini)[![Image 12: gpt-4.1](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4.1.png) GPT-4.1 Smartest non-reasoning model](https://platform.openai.com/docs/models/gpt-4.1)[![Image 13: gpt-4.1-mini](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4.1-mini.png) GPT-4.1 mini Smaller, faster version of GPT-4.1](https://platform.openai.com/docs/models/gpt-4.1-mini)[![Image 14: gpt-4.1-nano](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4.1-nano.png) GPT-4.1 nano Fastest, most cost-efficient version of GPT-4.1](https://platform.openai.com/docs/models/gpt-4.1-nano)[![Image 15: o1-pro](https://cdn.openai.com/API/docs/images/model-page/model-icons/o1-pro.png) o1-pro Version of o1 with more compute for better responses](https://platform.openai.com/docs/models/o1-pro)[![Image 16: computer-use-preview](https://cdn.openai.com/API/docs/images/model-page/model-icons/computer-use-preview.png) computer-use-preview Specialized model for computer use tool](https://platform.openai.com/docs/models/computer-use-preview)[![Image 17: gpt-4o-mini-search-preview](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4o-mini-search-preview.png) GPT-4o mini Search Preview Fast, affordable small model for web search](https://platform.openai.com/docs/models/gpt-4o-mini-search-preview)[![Image 18: gpt-4o-search-preview](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4o-search-preview.png) GPT-4o Search Preview GPT model for web search in Chat Completions](https://platform.openai.com/docs/models/gpt-4o-search-preview)[![Image 19: gpt-4.5-preview](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4-5-preview.png) GPT-4.5 Preview (Deprecated) Deprecated large model.](https://platform.openai.com/docs/models/gpt-4.5-preview)[![Image 20: o3-mini](https://cdn.openai.com/API/docs/images/model-page/model-icons/o3-mini.png) o3-mini A small model alternative to o3](https://platform.openai.com/docs/models/o3-mini)[![Image 21: gpt-4o-mini-audio-preview](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4o-mini-audio-preview.png) GPT-4o mini Audio Smaller model capable of audio inputs and outputs](https://platform.openai.com/docs/models/gpt-4o-mini-audio-preview)[![Image 22: gpt-4o-mini-realtime-preview](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4o-mini-realtime-preview.png) GPT-4o mini Realtime Smaller realtime model for text and audio inputs and outputs](https://platform.openai.com/docs/models/gpt-4o-mini-realtime-preview)[![Image 23: o1](https://cdn.openai.com/API/docs/images/model-page/model-icons/o1.png) o1 Previous full o-series reasoning model](https://platform.openai.com/docs/models/o1)[![Image 24: omni-moderation-latest](https://cdn.openai.com/API/docs/images/model-page/model-icons/omni-moderation-latest.png) omni-moderation Identify potentially harmful content in text and images](https://platform.openai.com/docs/models/omni-moderation-latest)[![Image 25: o1-mini](https://cdn.openai.com/API/docs/images/model-page/model-icons/o1-mini.png) o1-mini Deprecated A small model alternative to o1](https://platform.openai.com/docs/models/o1-mini)[![Image 26: o1-preview](https://cdn.openai.com/API/docs/images/model-page/model-icons/o1-preview.png) o1 Preview Deprecated Preview of our first o-series reasoning model](https://platform.openai.com/docs/models/o1-preview)[![Image 27: gpt-4o](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4o.png) GPT-4o Fast, intelligent, flexible GPT model](https://platform.openai.com/docs/models/gpt-4o)[![Image 28: gpt-4o-audio-preview](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4o-audio-preview.png) GPT-4o Audio GPT-4o models capable of audio inputs and outputs](https://platform.openai.com/docs/models/gpt-4o-audio-preview)[![Image 29: gpt-4o-mini](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4o-mini.png) GPT-4o mini Fast, affordable small model for focused tasks](https://platform.openai.com/docs/models/gpt-4o-mini)[![Image 30: gpt-4o-mini-audio-preview](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4o-mini-audio-preview.png) GPT-4o mini Audio Smaller model capable of audio inputs and outputs](https://platform.openai.com/docs/models/gpt-4o-mini-audio-preview)[![Image 31: gpt-4o-mini-realtime-preview](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4o-mini-realtime-preview.png) GPT-4o mini Realtime Smaller realtime model for text and audio inputs and outputs](https://platform.openai.com/docs/models/gpt-4o-mini-realtime-preview)[![Image 32: gpt-4o-realtime-preview](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4o-realtime-preview.png) GPT-4o Realtime Model capable of realtime text and audio inputs and outputs](https://platform.openai.com/docs/models/gpt-4o-realtime-preview)[![Image 33: gpt-4-turbo](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4-turbo.png) GPT-4 Turbo An older high-intelligence GPT model](https://platform.openai.com/docs/models/gpt-4-turbo)[![Image 34: babbage-002](https://cdn.openai.com/API/docs/images/model-page/model-icons/babbage-002.png) babbage-002 Replacement for the GPT-3 ada and babbage base models](https://platform.openai.com/docs/models/babbage-002)[![Image 35: chatgpt-4o-latest](https://cdn.openai.com/API/docs/images/model-page/model-icons/chatgpt-4o-latest.png) ChatGPT-4o GPT-4o model used in ChatGPT](https://platform.openai.com/docs/models/chatgpt-4o-latest)[![Image 36: codex-mini-latest](https://cdn.openai.com/API/docs/images/model-page/model-icons/codex-mini-latest.png) codex-mini-latest Fast reasoning model optimized for the Codex CLI](https://platform.openai.com/docs/models/codex-mini-latest)[![Image 37: dall-e-2](https://cdn.openai.com/API/docs/images/model-page/model-icons/dall-e-2.png) DALL·E 2 Our first image generation model](https://platform.openai.com/docs/models/dall-e-2)[![Image 38: dall-e-3](https://cdn.openai.com/API/docs/images/model-page/model-icons/dall-e-3.png) DALL·E 3 Previous generation image generation model](https://platform.openai.com/docs/models/dall-e-3)[![Image 39: davinci-002](https://cdn.openai.com/API/docs/images/model-page/model-icons/davinci-002.png) davinci-002 Replacement for the GPT-3 curie and davinci base models](https://platform.openai.com/docs/models/davinci-002)[![Image 40: gpt-3.5-turbo](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-3-5-turbo.png) GPT-3.5 Turbo Legacy GPT model for cheaper chat and non-chat tasks](https://platform.openai.com/docs/models/gpt-3.5-turbo)[![Image 41: gpt-4](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4.png) GPT-4 An older high-intelligence GPT model](https://platform.openai.com/docs/models/gpt-4)[![Image 42: gpt-4-turbo-preview](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4-turbo-preview.png) GPT-4 Turbo Preview An older fast GPT model](https://platform.openai.com/docs/models/gpt-4-turbo-preview)[![Image 43: gpt-4o-mini-transcribe](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4o-mini-transcribe.png) GPT-4o mini Transcribe Speech-to-text model powered by GPT-4o mini](https://platform.openai.com/docs/models/gpt-4o-mini-transcribe)[![Image 44: gpt-4o-mini-tts](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4o-mini-tts.png) GPT-4o mini TTS Text-to-speech model powered by GPT-4o mini](https://platform.openai.com/docs/models/gpt-4o-mini-tts)[![Image 45: gpt-4o-transcribe](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4o-transcribe.png) GPT-4o Transcribe Speech-to-text model powered by GPT-4o](https://platform.openai.com/docs/models/gpt-4o-transcribe)[![Image 46: gpt-5-chat-latest](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-5-chat-latest.png) GPT-5 Chat GPT-5 model used in ChatGPT](https://platform.openai.com/docs/models/gpt-5-chat-latest)[![Image 47: gpt-image-1](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-image-1.png) GPT Image 1 State-of-the-art image generation model](https://platform.openai.com/docs/models/gpt-image-1)[![Image 48: gpt-oss-120b](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-oss-120b.png) gpt-oss-120b Most powerful open-weight model, fits into an H100 GPU](https://platform.openai.com/docs/models/gpt-oss-120b)[![Image 49: gpt-oss-20b](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-oss-20b.png) gpt-oss-20b Medium-sized open-weight model for low latency](https://platform.openai.com/docs/models/gpt-oss-20b)[![Image 50: text-embedding-3-large](https://cdn.openai.com/API/docs/images/model-page/model-icons/text-embedding-3-large.png) text-embedding-3-large Most capable embedding model](https://platform.openai.com/docs/models/text-embedding-3-large)[![Image 51: text-embedding-3-small](https://cdn.openai.com/API/docs/images/model-page/model-icons/text-embedding-3-small.png) text-embedding-3-small Small embedding model](https://platform.openai.com/docs/models/text-embedding-3-small)[![Image 52: text-embedding-ada-002](https://cdn.openai.com/API/docs/images/model-page/model-icons/text-embedding-ada-002.png) text-embedding-ada-002 Older embedding model](https://platform.openai.com/docs/models/text-embedding-ada-002)[![Image 53: text-moderation-latest](https://cdn.openai.com/API/docs/images/model-page/model-icons/text-moderation-latest.png) text-moderation Deprecated Previous generation text-only moderation model](https://platform.openai.com/docs/models/text-moderation-latest)[![Image 54: text-moderation-stable](https://cdn.openai.com/API/docs/images/model-page/model-icons/text-moderation-stable.png) text-moderation-stable Deprecated Previous generation text-only moderation model](https://platform.openai.com/docs/models/text-moderation-stable)[![Image 55: tts-1](https://cdn.openai.com/API/docs/images/model-page/model-icons/tts-1.png) TTS-1 Text-to-speech model optimized for speed](https://platform.openai.com/docs/models/tts-1)[![Image 56: tts-1-hd](https://cdn.openai.com/API/docs/images/model-page/model-icons/tts-1-hd.png) TTS-1 HD Text-to-speech model optimized for quality](https://platform.openai.com/docs/models/tts-1-hd)[![Image 57: whisper-1](https://cdn.openai.com/API/docs/images/model-page/model-icons/whisper-1.png) Whisper General-purpose speech recognition model](https://platform.openai.com/docs/models/whisper-1)
